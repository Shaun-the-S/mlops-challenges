{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Deploy to an online endpoint\n",
        "\n",
        "To consume a model from an application, you can deploy the model to an online endpoint. You'll create an MLflow model from local files and test the endpoint.\n",
        "\n",
        "## Before you start\n",
        "\n",
        "You'll need the latest version of the  **azure-ai-ml** package to run the code in this notebook. Run the cell below to verify that it is installed.\n",
        "\n",
        "> **Note**:\n",
        "> If the **azure-ai-ml** package is not installed, run `pip install azure-ai-ml` to install it."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pip show azure-ai-ml"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Name: azure-ai-ml\nVersion: 1.28.1\nSummary: Microsoft Azure Machine Learning Client Library for Python\nHome-page: https://github.com/Azure/azure-sdk-for-python\nAuthor: Microsoft Corporation\nAuthor-email: azuresdkengsysadmins@microsoft.com\nLicense: MIT License\nLocation: /anaconda/envs/azureml_py38/lib/python3.10/site-packages\nRequires: azure-common, azure-core, azure-mgmt-core, azure-monitor-opentelemetry, azure-storage-blob, azure-storage-file-datalake, azure-storage-file-share, colorama, isodate, jsonschema, marshmallow, msrest, pydash, pyjwt, pyyaml, six, strictyaml, tqdm, typing-extensions\nRequired-by: \nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1667393334445
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Connect to your workspace\n",
        "\n",
        "With the required SDK packages installed, now you're ready to connect to your workspace.\n",
        "\n",
        "To connect to a workspace, we need identifier parameters - a subscription ID, resource group name, and workspace name. Since you're working with a compute instance, managed by Azure Machine Learning, you can use the default values to connect to the workspace."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1754574258961
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a handle to workspace\n",
        "ml_client = MLClient.from_config(credential=credential)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /config.json\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "gather": {
          "logged": 1754574279357
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Define and create an endpoint\n",
        "\n",
        "Ultimately, the goal is to deploy a model to an endpoint. Therefore, you first need to create an endpoint. The endpoint will be a HTTPS endpoint that an application can call to receive predictions from the model. An application can consume an endpoint by using its URI, and authenticating with a key or token.\n",
        "\n",
        "Run the following cell to define the endpoint. Note that the name of the endpoint has to be unique. You'll use the `datetime` function to generate a unique name."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import ManagedOnlineEndpoint\n",
        "import datetime\n",
        "\n",
        "online_endpoint_name = \"endpoint-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
        "\n",
        "# create an online endpoint\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=online_endpoint_name,\n",
        "    description=\"Online endpoint for MLflow diabetes model\",\n",
        "    auth_mode=\"key\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1754574307950
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Next, you'll create the endpoint by running the following cell. This may take several minutes. While your endpoint is being created, you can read about [what are Azure Machine Learning endpoints](https://learn.microsoft.com/azure/machine-learning/concept-endpoints)."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.begin_create_or_update(endpoint).result()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://endpoint-08071345451323.eastus.inference.ml.azure.com/score', 'openapi_uri': 'https://endpoint-08071345451323.eastus.inference.ml.azure.com/swagger.json', 'name': 'endpoint-08071345451323', 'description': 'Online endpoint for MLflow diabetes model', 'tags': {}, 'properties': {'createdBy': 'm m', 'createdAt': '2025-08-07T13:45:52.695824+0000', 'lastModifiedAt': '2025-08-07T13:45:52.695824+0000', 'azureml.onlineendpointid': '/subscriptions/6a454eec-81c8-4ed4-99d5-c1c45c82adb4/resourcegroups/rg-dp100-l5c3faefaaeab4f58ab/providers/microsoft.machinelearningservices/workspaces/mlw-dp100-l5c3faefaaeab4f58ab/onlineendpoints/endpoint-08071345451323', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/6a454eec-81c8-4ed4-99d5-c1c45c82adb4/providers/Microsoft.MachineLearningServices/locations/eastus/mfeOperationsStatus/oeidp:94e3822e-8072-461f-b839-e4b31dd29780:b5fab015-18f0-49d1-b021-6a0e150d7f70?api-version=2022-02-01-preview'}, 'print_as_yaml': False, 'id': '/subscriptions/6a454eec-81c8-4ed4-99d5-c1c45c82adb4/resourceGroups/rg-dp100-l5c3faefaaeab4f58ab/providers/Microsoft.MachineLearningServices/workspaces/mlw-dp100-l5c3faefaaeab4f58ab/onlineEndpoints/endpoint-08071345451323', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/ci5c3faefaaeab4f58ab/code/Users/mnbmedias/mlops-challenges', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7939b6bdf700>, 'auth_mode': 'key', 'location': 'eastus', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x7939b6bdfcd0>, 'traffic': {}, 'mirror_traffic': {}, 'kind': 'Managed'})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1754574414491
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> IMPORTANT! Wait until the endpoint is created successfully before continuing! A green notification should appear in the studio. </p>\n",
        "\n",
        "## Configure the deployment\n",
        "\n",
        "You can deploy multiple models to an endpoint. This is mostly useful when you want to update the deployed model while keeping the current model in production. You'll need to configure the deployment to specify which model needs to be deployed to an endpoint. In the following cell, you'll refer to the model trained and stored in the local `model` folder (stored in the same folder as this notebook). Note that since you're working with an MLflow model, you don't need to specify the environment or scoring script.\n",
        "\n",
        "You'll also specify the infrastructure needed for the model to be deployed."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Model, ManagedOnlineDeployment\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "# create a blue deployment\n",
        "model = Model(\n",
        "    path=\"./model\",\n",
        "    type=AssetTypes.MLFLOW_MODEL,\n",
        "    description=\"my sample mlflow model\",\n",
        ")\n",
        "\n",
        "blue_deployment = ManagedOnlineDeployment(\n",
        "    name=\"blue2\",\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    model=model,\n",
        "    instance_type=\"Standard_D2as_v4\",\n",
        "    instance_count=1,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1754575628056
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Create the deployment\n",
        "\n",
        "Finally, you can actually deploy the model to the endpoint by running the following cell:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.online_deployments.begin_create_or_update(blue_deployment).result()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Check: endpoint endpoint-08071345451323 exists\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "................................................................................"
        },
        {
          "output_type": "error",
          "ename": "HttpResponseError",
          "evalue": "(ImageBuildFailure) Deployment failed due to no Environment Image available. Check Environment Build Log in ML Studio Workspace or Workspace storage for potential failures. Environment info: Name: 751503b57491b435f555ac05790c311fd30db5943e895d1407fdb13a8d4d7af0, Version: bdd3a669eef3f494ec819f2ce8b9c3021434b7e16fdb33d96811c8a797890d37, you may be able to find the build log under the storage account 'mlwdp100storagea75c64fae' in the container 'aml-environment-image-build' at the path '751503b57491b435f555ac05790c311fd30db5943e895d1407fdb13a8d4d7af0/bdd3a669eef3f494ec819f2ce8b9c3021434b7e16fdb33d96811c8a797890d37/imgbldrun_895c20a/image_build_log.txt'. Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-imagebuildfailure\nCode: ImageBuildFailure\nMessage: Deployment failed due to no Environment Image available. Check Environment Build Log in ML Studio Workspace or Workspace storage for potential failures. Environment info: Name: 751503b57491b435f555ac05790c311fd30db5943e895d1407fdb13a8d4d7af0, Version: bdd3a669eef3f494ec819f2ce8b9c3021434b7e16fdb33d96811c8a797890d37, you may be able to find the build log under the storage account 'mlwdp100storagea75c64fae' in the container 'aml-environment-image-build' at the path '751503b57491b435f555ac05790c311fd30db5943e895d1407fdb13a8d4d7af0/bdd3a669eef3f494ec819f2ce8b9c3021434b7e16fdb33d96811c8a797890d37/imgbldrun_895c20a/image_build_log.txt'. Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-imagebuildfailure",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOperationFailed\u001b[0m                           Traceback (most recent call last)",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/azure/core/polling/base_polling.py:788\u001b[0m, in \u001b[0;36mLROBasePolling.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 788\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m BadStatus \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/azure/core/polling/base_polling.py:820\u001b[0m, in \u001b[0;36mLROBasePolling._poll\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _failed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus()):\n\u001b[0;32m--> 820\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OperationFailed(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOperation failed or canceled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    822\u001b[0m final_get_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_operation\u001b[38;5;241m.\u001b[39mget_final_get_url(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipeline_response)\n",
            "\u001b[0;31mOperationFailed\u001b[0m: Operation failed or canceled",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monline_deployments\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin_create_or_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblue_deployment\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/azure/core/polling/_poller.py:254\u001b[0m, in \u001b[0;36mLROPoller.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PollingReturnType_co:\n\u001b[1;32m    246\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the result of the long running operation, or\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03m    the result available after the specified timeout.\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;124;03m    :raises ~azure.core.exceptions.HttpResponseError: Server problem with the query.\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 254\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_polling_method\u001b[38;5;241m.\u001b[39mresource()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/azure/core/tracing/decorator.py:138\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m span_attributes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    137\u001b[0m                 span\u001b[38;5;241m.\u001b[39madd_attribute(key, value)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# Native path\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/azure/core/polling/_poller.py:273\u001b[0m, in \u001b[0;36mLROPoller.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thread\u001b[38;5;241m.\u001b[39mjoin(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;66;03m# Let's handle possible None in forgiveness here\u001b[39;00m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;66;03m# https://github.com/python/mypy/issues/8165\u001b[39;00m\n\u001b[0;32m--> 273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# Was None\u001b[39;00m\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/azure/core/polling/_poller.py:188\u001b[0m, in \u001b[0;36mLROPoller._start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Start the long running operation.\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;124;03mOn completion, runs any callbacks.\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_polling_method\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m AzureError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m error\u001b[38;5;241m.\u001b[39mcontinuation_token:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/azure/core/polling/base_polling.py:803\u001b[0m, in \u001b[0;36mLROBasePolling.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(\n\u001b[1;32m    797\u001b[0m         response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipeline_response\u001b[38;5;241m.\u001b[39mhttp_response,\n\u001b[1;32m    798\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(err),\n\u001b[1;32m    799\u001b[0m         error\u001b[38;5;241m=\u001b[39merr,\n\u001b[1;32m    800\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OperationFailed \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 803\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pipeline_response\u001b[38;5;241m.\u001b[39mhttp_response, error\u001b[38;5;241m=\u001b[39merr) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n",
            "\u001b[0;31mHttpResponseError\u001b[0m: (ImageBuildFailure) Deployment failed due to no Environment Image available. Check Environment Build Log in ML Studio Workspace or Workspace storage for potential failures. Environment info: Name: 751503b57491b435f555ac05790c311fd30db5943e895d1407fdb13a8d4d7af0, Version: bdd3a669eef3f494ec819f2ce8b9c3021434b7e16fdb33d96811c8a797890d37, you may be able to find the build log under the storage account 'mlwdp100storagea75c64fae' in the container 'aml-environment-image-build' at the path '751503b57491b435f555ac05790c311fd30db5943e895d1407fdb13a8d4d7af0/bdd3a669eef3f494ec819f2ce8b9c3021434b7e16fdb33d96811c8a797890d37/imgbldrun_895c20a/image_build_log.txt'. Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-imagebuildfailure\nCode: ImageBuildFailure\nMessage: Deployment failed due to no Environment Image available. Check Environment Build Log in ML Studio Workspace or Workspace storage for potential failures. Environment info: Name: 751503b57491b435f555ac05790c311fd30db5943e895d1407fdb13a8d4d7af0, Version: bdd3a669eef3f494ec819f2ce8b9c3021434b7e16fdb33d96811c8a797890d37, you may be able to find the build log under the storage account 'mlwdp100storagea75c64fae' in the container 'aml-environment-image-build' at the path '751503b57491b435f555ac05790c311fd30db5943e895d1407fdb13a8d4d7af0/bdd3a669eef3f494ec819f2ce8b9c3021434b7e16fdb33d96811c8a797890d37/imgbldrun_895c20a/image_build_log.txt'. Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-imagebuildfailure"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1754577463568
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "The deployment of the model may take 10-15 minutes. While waiting for the model to be deployed, you can learn more about [managed endpoints in this video](https://www.youtube.com/watch?v=SxFGw_OBxNM&ab_channel=MicrosoftDeveloper).\n",
        "\n",
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> IMPORTANT! Wait until the deployment is completed before continuing! A green notification should appear in the studio.</p>\n",
        "\n",
        "Since you only have one model deployed to the endpoint, you want this deployment to take 100% of the traffic. If you deploy multiple models to the endpoint, you could use the same approach to distribute traffic across the deployed models."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# blue deployment takes 100 traffic\n",
        "endpoint.traffic = {\"blue\": 100}\n",
        "ml_client.begin_create_or_update(endpoint).result()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667341237843
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> IMPORTANT! Wait until the blue deployment is configured before continuing! A green notification should appear in the studio. </p> \n",
        "\n",
        "## Test the deployment\n",
        "\n",
        "Let's test the deployed model by invoking the endpoint. A JSON file with sample data is used as input. The trained model predicts whether a patient has diabetes or not, based on medical data like age, BMI, and the number of pregnancies. A `[0]` indicates a patient doesn't have diabetes. A `[1]` means a patient does have diabetes."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test the blue deployment with some sample data\n",
        "response = ml_client.online_endpoints.invoke(\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    deployment_name=\"blue\",\n",
        "    request_file=\"sample-data.json\",\n",
        ")\n",
        "\n",
        "if response[1]=='1':\n",
        "    print(\"Diabetic\")\n",
        "else:\n",
        "    print (\"Not diabetic\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667385183402
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "Optionally, you can change the values in the `sample-data.json` file to try and get a different prediction."
      ],
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## List endpoints\n",
        "\n",
        "Although you can view all endpoints in the Studio, you can also list all endpoints using the SDK:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "endpoints = ml_client.online_endpoints.list()\n",
        "for endp in endpoints:\n",
        "    print(endp.name)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667395563837
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Get endpoint details\n",
        "\n",
        "If you want more information about a specific endpoint, you can explore the details using the SDK too."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the details for online endpoint\n",
        "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
        "\n",
        "# existing traffic details\n",
        "print(endpoint.traffic)\n",
        "\n",
        "# Get the scoring URI\n",
        "print(endpoint.scoring_uri)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667395538913
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Delete the endpoint and deployment\n",
        "\n",
        "As an endpoint is always available, it can't be paused to save costs. To avoid unnecessary costs, delete the endpoint."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.online_endpoints.begin_delete(name=online_endpoint_name)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1667395549933
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.10 - AzureML"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}